{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef98ac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU-only mode (CURRENTLY DISABLED - using GPU with memory growth instead)\n",
    "# Uncomment lines below if you want to force CPU instead:\n",
    "\n",
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # Disable GPU\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'   # Reduce TF logging\n",
    "# print(\"âœ“ GPU disabled - TensorFlow will use CPU only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "640910f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ GPU memory growth enabled for 1 GPU(s)\n",
      "  GPU: /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# GPU Configuration with Memory Growth\n",
    "# This allows TensorFlow to allocate GPU memory as needed instead of grabbing it all at once\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Enable memory growth for all GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        \n",
    "        print(f\"âœ“ GPU memory growth enabled for {len(gpus)} GPU(s)\")\n",
    "        print(f\"  GPU: {gpus[0].name}\")\n",
    "        \n",
    "        # Optional: Set a memory limit (uncomment if needed)\n",
    "        # tf.config.set_logical_device_configuration(\n",
    "        #     gpus[0],\n",
    "        #     [tf.config.LogicalDeviceConfiguration(memory_limit=2048)]  # 2GB limit\n",
    "        # )\n",
    "        \n",
    "    except RuntimeError as e:\n",
    "        print(f\"âœ— Error configuring GPU: {e}\")\n",
    "        print(\"  TensorFlow may have already been initialized\")\n",
    "else:\n",
    "    print(\"âš ï¸  No GPU found - will use CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3c646d",
   "metadata": {},
   "source": [
    "---\n",
    "## âš ï¸ IMPORTANT: Restart Kernel Now!\n",
    "\n",
    "**Before running Cell 2 above, you MUST restart the kernel:**\n",
    "\n",
    "1. Click `Kernel` â†’ `Restart Kernel`  \n",
    "   OR press `0, 0` (zero twice quickly)\n",
    "2. Click \"Restart\" in the dialog\n",
    "3. Then run Cell 2 first\n",
    "4. Then run remaining cells in order\n",
    "\n",
    "**Why?** TensorFlow is already loaded and can't change GPU settings mid-session.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040ffbee",
   "metadata": {},
   "source": [
    "This is My First RNN Model for the Purpose of Learning the working of RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceabe843",
   "metadata": {},
   "source": [
    "We will be Building the most simple Sentimental Analysis Model\n",
    "Text -> Vector (Embedding) -> RNN Forward Prop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98dabcc",
   "metadata": {},
   "source": [
    "## ğŸ”§ Setup Instructions - GPU Mode with Memory Growth\n",
    "\n",
    "### Configuration: Using GPU with dynamic memory allocation\n",
    "\n",
    "**How to run:**\n",
    "\n",
    "1. **Restart Kernel**: `Kernel` â†’ `Restart Kernel` (or press `0, 0` twice)\n",
    "2. **Run Cell 2 FIRST** - This enables GPU memory growth\n",
    "3. **Then run remaining cells in order**\n",
    "\n",
    "### What's different:\n",
    "- âœ… GPU will allocate memory **gradually** as needed\n",
    "- âœ… Batch size reduced to 16 (uses less memory)\n",
    "- âœ… Using 5000 training samples (manageable size)\n",
    "\n",
    "### If GPU still fails:\n",
    "1. Close Chrome/Firefox and other GPU-using apps\n",
    "2. Try even smaller batch size: change `batch_size=16` to `batch_size=8`\n",
    "3. Reduce dataset: change `x_train[:5000]` to `x_train[:2000]`\n",
    "4. Or switch to CPU mode: comment Cell 2, uncomment Cell 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a98b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "docs = [\n",
    "    'go india',\n",
    "    'india india',\n",
    "    'hip hip hurray',\n",
    "    'jeetega bhai jeetega india jeetega',\n",
    "    'bharat mata ki jai',\n",
    "    'kohli kohli',\n",
    "    'rohit rohit',\n",
    "    'inquilab zindabad'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e536a8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenisation\n",
    "from keras_preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(oov_token = '<nothing>')\n",
    "tokenizer.fit_on_texts(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7619d970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72eb9b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = tokenizer.texts_to_sequences(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78979465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7, 2],\n",
       " [2, 2],\n",
       " [4, 4, 8],\n",
       " [3, 9, 3, 2, 3],\n",
       " [10, 11, 12, 13],\n",
       " [5, 5],\n",
       " [6, 6],\n",
       " [14, 15]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f72606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences\n",
    "seq = pad_sequences(seq, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a53cc9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  2,  0,  0,  0],\n",
       "       [ 2,  2,  0,  0,  0],\n",
       "       [ 4,  4,  8,  0,  0],\n",
       "       [ 3,  9,  3,  2,  3],\n",
       "       [10, 11, 12, 13,  0],\n",
       "       [ 5,  5,  0,  0,  0],\n",
       "       [ 6,  6,  0,  0,  0],\n",
       "       [14, 15,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e87f75dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, Embedding, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef0aa197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/the-aditya-10/New Volume/Aditya/CODING/AI, ML, DL, DS/RNN-Learning/venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762505499.905933   13617 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 130 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2050, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model for IMDB sentiment analysis\n",
    "vocab_size = 10000  # IMDB dataset uses top 10k words by default\n",
    "embedding_dim = 32\n",
    "max_length = 200\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
    "model.add(SimpleRNN(32, return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c2098e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (X_test, Y_test) = imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c855b123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (25000, 200)\n",
      "X_test shape: (25000, 200)\n"
     ]
    }
   ],
   "source": [
    "# Pad the IMDB sequences to a fixed length\n",
    "import numpy as np\n",
    "\n",
    "def pad_sequences_custom(sequences, maxlen=None, padding='post', truncating='post', value=0):\n",
    "    \"\"\"Simple padding function compatible with NumPy 2.0\"\"\"\n",
    "    lengths = [len(s) for s in sequences]\n",
    "    if maxlen is None:\n",
    "        maxlen = max(lengths) if lengths else 0\n",
    "    \n",
    "    result = np.full((len(sequences), maxlen), value, dtype='int32')\n",
    "    \n",
    "    for i, s in enumerate(sequences):\n",
    "        if len(s) > maxlen:\n",
    "            if truncating == 'pre':\n",
    "                trunc = s[-maxlen:]\n",
    "            else:\n",
    "                trunc = s[:maxlen]\n",
    "        else:\n",
    "            trunc = s\n",
    "        \n",
    "        if padding == 'post':\n",
    "            result[i, :len(trunc)] = trunc\n",
    "        else:\n",
    "            result[i, -len(trunc):] = trunc\n",
    "    \n",
    "    return result\n",
    "\n",
    "max_length = 200  # Use first 200 words of each review\n",
    "x_train = pad_sequences_custom(x_train, maxlen=max_length, padding='post', truncating='post')\n",
    "X_test = pad_sequences_custom(X_test, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f26adc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss= 'binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cb8599c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.7182 - loss: 0.4995 - val_accuracy: 0.5050 - val_loss: 0.7656\n",
      "Epoch 2/2\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.7182 - loss: 0.4995 - val_accuracy: 0.5050 - val_loss: 0.7656\n",
      "Epoch 2/2\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.7054 - loss: 0.5233 - val_accuracy: 0.5260 - val_loss: 0.6949\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.7054 - loss: 0.5233 - val_accuracy: 0.5260 - val_loss: 0.6949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x77001aa0e0c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train with smaller batch size for GPU memory efficiency\n",
    "# Using subset of data for faster training (increase if you want)\n",
    "model.fit(x_train[:5000], y_train[:5000], \n",
    "          epochs=2, \n",
    "          batch_size=16,  # Reduced from 32 to use less GPU memory\n",
    "          validation_data=(X_test[:1000], Y_test[:1000]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
